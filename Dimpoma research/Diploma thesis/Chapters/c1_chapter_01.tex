%!TEX root = ../thesis.tex

\chapter{Методи дослідження прихованих марковських моделей}
\label{chap: review}

У цьому розділі будуть окреслені основні поняття та методи, які використовуватимуться у подальших викладках при розв'язуванні поставлених в межах дипломної роботи завдань.

\section{Основні поняття і властивості ланцюгів Маркова}

Нехай $\left\{ X^t \right\}_{t\geqslant 1}$~--- послідовність випадкових величин зі значеннями в скінченній або зліченній множині $E=\{ e_1,e_2,\ldots \}$. 

\begin{definition}\label{def: markovian property}
    Послідовність $\left\{ X^t \right\}_{t\geqslant 1}$ утворює ланцюг Маркова, якщо:
    \begin{align*}
        & \forall t\geqslant 2 \quad \forall i^1,\,i^2,\ldots,\,i^{t+1} \in E: \\
	    & P\left( X^{t+1}=i^{t+1} \, |\, X^t=i^t,\ldots\,,\, X^1=i^1 \right)=P\left( X^{t+1}=i^{t+1} \, |\, X^t=i^t \right)
    \end{align*}
    Цю умову називають марковською властивістю.
\end{definition}

Множина $E$ називається множиною станів ланцюга, а випадкова величина $X^t$ трактується як стан системи в момент часу $t$. Надалі у ході дослідження по замовчуванню розглядатимуться так звані однорідні ланцюги Маркова, для яких ймовірності переходу $P\left( X^{t+1}=j\,|\,X^{t}=i \right)$ з одного стану $i \in E$ в інший $j \in E$ не залежать від $t$.

Ймовірність $p_{ij} = P\left( X^{t+1}=j\,|\,X^{t}=i \right)$ називається перехідною ймовірністю однорідного ланцюга Маркова. Матриця $A$, складена із цих імовірностей, називається матрицею перехідних імовірностей:
\begin{equation*}
    A = \Bigl( p_{ij} \Bigr)_{i,j \in E} = \Bigl( P\left( X^{t+1}=j\,|\,X^{t}=i \right) \Bigr)_{i,j \in E}
\end{equation*} 

Ця матриця є стохастичною, тобто
\begin{equation*}
    \forall i,\,j \in E: p_{ij} \geqslant 0\ \text{ та }\ \forall i \in E: \sum\limits_{j \in E} p_{ij} = 1
\end{equation*}

Окрім матриці $A$, для ланцюга Маркова слід задати вектор початкового розподілу ймовірностей
\begin{equation*}
    \pi = \Bigl( \pi_i \Bigr)_{i \in E} = \Bigl( P\left( X^{1} = i \right) \Bigr)_{i \in E}
\end{equation*}

Надалі позначатимемо ланцюг Маркова з матрицею перехідних імовірностей $A$ та початковим розподілом $\pi$ як $\lambda=(\pi,\,A)$.

Скінченновимірні розподіли~\cite{Norris1997} ланцюга Маркова $\lambda=(\pi,\,A)$ повністю визначаються матрицею перехідних імовірностей $A$ та вектором початкового розподілу ймовірностей $\pi$. А саме:
\begin{align}
    &\forall t\geqslant 2 \quad \forall i^1,\,i^2,\ldots,\,i^{t} \in E: \notag \\
    &P\left( X^{1}=i^{1},\,X^{2}=i^{2},\ldots\,,\, X^{t-1}=i^{t-1},\, X^{t}=i^{t} \right) = \pi_{i^1} \cdot p_{i^1i^2} \cdot \ldots \cdot p_{i^{t-1}i^{t}} \label{eq: finite-dimensional distributions}
\end{align}

\section{Поняття прихованої марковської моделі}

Розглянемо послідовність випадкових величин $\left\{ X^t \right\}_{t\geqslant 1}$ на скінченній або зліченній множині станів $E=\{e_1,e_2,\ldots\}$ та нехай $\left\{ Y^t \right\}_{t\geqslant 1}$~--- послідовність випадкових величин на скінченній або зліченній множині $F=\{f_1,f_2,\ldots\}$. 

\begin{definition}\label{def: HMM}
    Пара $\left\{\left( X^t,\,Y^t \right)\right\}_{t\geqslant 1}$, задана на декартовому добутку $E\times F$, є прихованою марковською моделлю за виконання таких умов:
    \begin{enumerate}
        \item послідовність $\left\{ X^t \right\}_{t\geqslant 1}$ утворює ланцюг Маркова з початковим розподілом $\pi$ та матрицею перехідних імовірностей $A$;
        \item послідовність $\left\{\left( X^t,\,Y^t \right)\right\}_{t\geqslant 1}$ є ланцюгом Маркова;
        \item випадкові величини $Y^1,\,Y^2,\ldots,\,Y^t$ є умовно незалежними при заданому наборі величин $X^1,\,X^2,\ldots,\,X^t:$
        \begin{multline*}
            \forall t\geqslant 2 \quad \forall j^1,\,j^2,\ldots,\,j^t \in F \quad \forall i^1,\,i^2,\ldots,\,i^t \in E: \\
            P\left( Y^1=j^1,\ldots,\,Y^t=j^t \,|\, X^1=i^1,\ldots,\,X^t=i^t \right) = \\
            = \prod\limits_{k=1}^{t}P\left( Y^k=j^k \,|\, X^1=i^1,\ldots,\,X^t=i^t \right)
        \end{multline*}
        \item умовний розподіл випадкової величини $Y^k$ в момент часу $k$ при заданих $X^1,\,X^2,\ldots,\,X^t$ залежить лише від $X^k:$
        \begin{align*}
            & \forall t\geqslant 2 \quad \forall k=\overline{1,t} \quad \forall j^k \in F \quad \forall i^1,\,i^2,\ldots,\,i^t \in E: \\
            & P\left( Y^k=j^k \,|\, X^1=i^1,\ldots,\,X^t=i^t \right) = P\left( Y^k=j^k \,|\, X^k=i^k \right)
        \end{align*}
    \end{enumerate}
\end{definition}

У парі $\left\{\left( X^t,\,Y^t \right)\right\}_{t\geqslant 1}$ послідовність $\left\{ X^t \right\}_{t\geqslant 1}$ називають <<прихованою>>, а послідовність $\left\{ Y^t \right\}_{t\geqslant 1}$~--- <<спостережуваною>>.

Окрім матриці $A$ та вектора $\pi$, які задають ланцюг Маркова $\left\{ X^t \right\}_{t\geqslant 1}$, прихована марковська модель визначається матрицею умовних імовірностей спостережень $j \in F$ при заданих прихованих станах $i \in E:$
\begin{equation*}
    B = \Bigl( B_{ij} \Bigr)_{i,j \in E \times F} = \Bigl( P\left( Y^{t}=j \,|\, X^{t}=i \right) \Bigr)_{i,j \in E \times F}
\end{equation*} 

Позначатимемо приховану марковську модель з початковим розподілом $\pi$, матрицею перехідних імовірностей $A$ та матрицею умовних імовірностей спостережень при заданих прихованих станах $B$ таким чином: $\lambda=(\pi,\,A,\,B)$.

\section{Ітераційний алгоритм Баума-Велша}

Нехай протягом деякого часу $t=\overline{1,T}$ спостерігається послідовність випадкових величин 
\begin{equation*}
    \left( Y^1=y^1,\ldots,\,Y^T=y^T \right)\ \Longleftrightarrow\ Y=y
\end{equation*}
деякої прихованої марковської моделі $\lambda=(\pi,\,A,\,B)$, параметри $\pi,\,A,\,B$ якої є невідомими. Постає питання: як за набором наявних даних віднайти оптимальні параметри моделі?

Скористаємося методом максимальної правдоподібності, шукаючи оцінку $\widehat{\lambda}=(\widehat{\pi},\,\widehat{A},\,\widehat{B})$ шляхом максимізації ймовірності вигляду:
\begin{equation*}
    \widehat{\lambda}=\argmax\limits_{\lambda} P\left( Y=y \,|\, \lambda \right)
\end{equation*}

Інакше кажучи, шукатимемо такі параметри моделі, які найкраще пояснюють отримані спостереження $y$. 

Ймовірність $P\left( Y=y \,|\, \lambda \right)$ називається функцією правдоподібності. Задача максимізації цієї функції є складною чи неможливою в цілому через громіздкість отриманого виразу: зважаючи на вигляд \eqref{eq: finite-dimensional distributions} скінченновимірних розподілів ланцюга Маркова та враховуючи умови 3)~й~4) означення прихованої марковської моделі (Озн. \ref{def: HMM}), функція правдоподібності набуває вигляду:
\begin{equation}\label{eq: likelihood function}
    P\left( Y=y \,|\, \lambda \right) = \sum\limits_{x \in E^T} P\left( X=x,\, Y=y \,|\, \lambda \right) = \sum\limits_{x \in E^T} \pi_{x^1} \cdot \prod\limits_{t=1}^{T-1} A_{x^t x^{t+1}} \cdot \prod\limits_{t=1}^{T} B_{x^ty^t} 
\end{equation}

Безпосередня максимізація за цією формулою вимагає охоплення близько $T\cdot|E|^T$ множників, де $T$, як правило, є великим. Однак, для прихованих марковських моделей можна застосувати інший підхід: модифікацію ЕМ-алгоритму~\cite[розділ 4]{Koski2001} для дослідження прихованих ланцюгів Маркова~--- ітераційний алгоритм Баума-Велша~\cite[розділ 15]{Koski2001}. 

Задавши деяке наближення невідомої моделі $\lambda^{(0)}=(\pi^{(0)},\,A^{(0)},\,B^{(0)})$, покладемо для наступної ітерації $n+1$
\begin{equation*}
    \lambda^{(n+1)} = \argmax\limits_{\lambda} Q\left( \lambda^{(n)},\,\lambda \right),
\end{equation*}
де
\begin{equation}\label{eq: Q quasi-log likelihood function}
    Q\left( \lambda^{(n)},\,\lambda \right) = \sum\limits_{x \in E^T}L_{\lambda^{(n)}} \ln L_{\lambda}
\end{equation}
є так званою функцією квазі-log правдоподібності, а вираз
\begin{equation*}
    L_{\lambda} \equiv P\left( X=x,\,Y=y \,|\, \lambda \right)
\end{equation*}
називається функцією повної правдоподібності.

Доведено~\cite[розділ 4]{Koski2001}, що така ітераційна процедура є збіжною і приводить до точки локального максимуму логарифма функції правдоподібності~\eqref{eq: likelihood function}. А оскільки точки екстремумів довільної функції та її логарифму збігаються, ця процедура розв'язує поставлену задачу.

Особливістю алгоритму навчання Баума-Велша є використання так званих змінних прямого~\eqref{eq: alpha, forward algorithm coefficients} та зворотного~\eqref{eq: beta, backward algorithm coefficients} ходу, за допомогою яких обчислення функції правдоподібності вимагає лише $T\cdot|E|^2$ добутків. Вказані коефіцієнти визначаються наступним чином:
\begin{align}
    & \forall x \in E: \notag \\
    & \alpha_t(x) = P\left( Y^1=y^1,\ldots,\,Y^t=y^t,\,X^t=x \,|\, \lambda^{(n)} \right) \label{eq: alpha, forward algorithm coefficients} \\
    & \beta_t(x) = P\left( Y^{t+1}=y^{t+1},\ldots,\,Y^T=y^T \,|\, X^t=x,\, \lambda^{(n)} \right) \label{eq: beta, backward algorithm coefficients}
\end{align}

Перевага цих коефіцієнтів полягає у тому, що їх можна обчислити рекурентно~\cite[розділ 5]{Nilsson2005} згідно з наведеними нижче співвідношеннями для змінних прямого ходу
\begin{align*}
    & t = 1              && \forall x \in E: \alpha_1(x)=\pi_{x}\,B_{x,y^1} \\
    & t = \overline{2,T} && \forall x \in E: \alpha_{t}(x)=\sum\limits_{x'\in E}\alpha_{t-1}(x')\,A_{x'x}\,B_{xy^{t}} 
\end{align*}
та змінних зворотного ходу
\begin{align*}
    & t = T                  && \forall x \in E: \beta_T(x)=1 \\
    & t = \overline{T-1,\,1} && \forall x \in E: \beta_t(x)=\sum\limits_{x' \in E}\beta_{t+1}(x')\,A_{x x'}\,B_{x'y^{t+1}}
\end{align*}

\newpage
\begin{remark}
    При великих значеннях довжини ланцюга виникає потреба у шкалюванні~\cite[розділ 5]{Nilsson2005} коефіцієнтів прямого та зворотного ходу, адже їхні значення стають нерозрізнювано малими для обчислювальних ресурсів. Процедура шкалювання полягає в наступному: на кожному кроці $t$ після обчислення істинних змінних~\eqref{eq: alpha, forward algorithm coefficients} слід виконати відповідне нормування
    \begin{equation*}
        \forall x \in E\ :\ \widehat{\alpha}_t(x) = \frac{\alpha_t(x)}{C_t},\ \text{де}\ C_t = \sum\limits_{x' \in E}\alpha_t(x'),
    \end{equation*}
    а тоді коефіцієнти~\eqref{eq: beta, backward algorithm coefficients} нормуються так:
    \begin{equation*}
        \forall x \in E\ :\ \widehat{\beta}_t(x) = \frac{\beta_t(x)}{C_t}
    \end{equation*}
\end{remark}

\section{Алгоритм Вітербі}
\label{section: Viterbi alorithm}

Отримавши оптимальну модель $\widehat{\lambda}=(\widehat{\pi},\,\widehat{A},\,\widehat{B})$ як розв'язок задачі навчання, перейдемо до так званої задачі декодування: віднайдемо ланцюжок прихованих станів системи. Алгоритм, який дозволяє ефективно розв’язати задачу декодування, називається алгоритмом Вітербі~\cite[розділ 6]{Nilsson2005}.

Отже, шукатимемо таку послідовність прихованих станів $\widehat{X}^1,\,\widehat{X}^2,\ldots,\,\widehat{X}^T$, яка найкращим чином описує наявні спостереження:
\begin{equation*}
    \widehat{X} = \argmax\limits_{x \in E^T} P\left( X=x \,|\, Y=y,\, \widehat{\lambda} \right) = \argmax\limits_{x \in E^T} P\left( X=x,\, Y=y \,|\, \widehat{\lambda} \right)
\end{equation*}

Введемо величини $\delta_t(x)$ максимальної ймовірності спостереження ланцюжка довжини $t$, що закінчується станом $x \in E$ в момент часу $t:$
\begin{equation*}\scaleq[0.9]{
    \delta_t(x)=\max\limits_{x^1,\ldots,\,x^{t-1}}P\left( X^1=x^1,\ldots,\,X^{t-1}=x^{t-1},\,X^t=x,\,Y^1=y^1,\ldots,\,Y^t=y^t \,|\, \widehat{\lambda}  \right)}
\end{equation*}

Вказані ймовірності можна визначити рекурентно:
\begin{align*}
    & t = 1              && \forall x \in E: \delta_1(x)=\pi_{x}\,B_{xy^1} \\
    & t = \overline{2,T} && \forall x \in E: \delta_{t}(x)=B_{xy^{t}}\cdot\max_{x' \in E}\Bigl\{ \delta_{t-1}(x')\,A_{x'x} \Bigr\}
\end{align*}

При цьому, щоб знайти оптимальний ланцюжок прихованих станів необхідно відстежувати аргумент, при якому досягається максимум $\delta_t(x)$ для кожного $t$ та $x$. Таким чином, алгоритм Вітербі знаходження найбільш імовірного ланцюжка прихованих станів є таким:

\begin{enumerate}
    \item крок ініціалізації:
    \begin{equation*}
        \forall x \in E\ :\ \delta_1(x)=\pi_{x}B_{xy^1}, \ \psi_1(x)=1
    \end{equation*}    
    \item обчислити коефіцієнти $\delta_t(x)$ та відповідні аргументи $\psi_t(x):$
    \begin{align*}
        &\forall t=\overline{1,T}, \ \forall x \in E: && \delta_{t}(x)=B_{xy^{t}}\cdot\max_{x'\in E}\Bigl\{\delta_{t-1}(x')\,A_{x'x}\Bigr\} \\
        &\forall t=\overline{1,T}, \ \forall x \in E: && \psi_{t}(x)=\argmax_{x'\in E}\Bigl\{\delta_{t-1}(x')\,A_{x'x}\Bigr\}
    \end{align*}
    \item покласти зворотну точку відліку:
    \begin{align*}
        &\widehat{\delta}=\max_{x \in E}\Bigl\{\delta_T(x)\Bigr\} \\
        &\widehat{\psi}=\argmax_{x \in E}\Bigl\{\delta_T(x)\Bigr\}
    \end{align*}
    \item визначити оптимальний ланцюжок станів (у зворотному порядку), починаючи з останнього $\widehat{x}^T=\widehat{\psi}:$
    \begin{equation*}
        \forall t=\overline{T-1,\,1}\ :\ \widehat{x}^t=\psi_{t+1}(\widehat{x}^{t+1})
    \end{equation*}
\end{enumerate}

\section{Властивості точкових оцінок}

Окреслимо основні інструменти математичної статистики, які будуть використані при побудові статистичних оцінок невідомих параметрів.

Вектор $\vv{X}=(X_1,\ldots,\,X_T)$ незалежних однаково розподілених випадкових величин з деякої параметричної сім'ї розподілів $\mathfrak{F}=\{ F_\theta(x),\ \theta \in \Theta \}$ називають вибіркою об'єму $T$. При цьому, параметр розподілу $\theta$ може бути невідомим. Функція від вибірки $S_T=S_T(\vv{X})$ називається статистикою. 

Якщо значення статистики $S_T(\vv{X})$ при заданій реалізації вибірки приймають за наближене значення невідомого параметра $\theta$ розподілу $F_\theta(x)$, тоді $S_T$ називають точковою оцінкою $\theta$. 

\begin{definition}
    Статистика $S_T$ називається змістовною оцінкою $\theta$, якщо вона збігається за ймовірністю до істинного значення оцінюваного параметра, тобто 
    \begin{equation*}
        \forall \theta \in \Theta\ :\ S_T \xrightarrow[T \longrightarrow \infty]{P} \theta \quad \Longleftrightarrow \quad \forall \varepsilon > 0\ : \lim\limits_{T \longrightarrow \infty} P\Bigl( \left|S_T - \theta\right| \geqslant \varepsilon \Bigr) = 0
    \end{equation*}
\end{definition}

\begin{definition}
    Статистика $S_T$ називається незміщеною оцінкою $\theta$, якщо її математичне сподівання дорівнює істинному значенню оцінюваного параметра, тобто
    \begin{equation*}
        \forall \theta \in \Theta\ :\ M_\theta S_T = \theta
    \end{equation*}
\end{definition}

Також зазначимо для набору незалежних однаково розподілених випадкових величин так званий закон великих чисел~\cite{Larsen2017}:

\begin{theorem}\label{theorem: law of big numbers}
    Нехай $\left\{ X_t \right\}_{t\geqslant 1}$~--- послідовність незалежних однаково розподілених випадкових величин зі скінченним математичним сподіванням $MX_1=m$. Тоді випадкова величина $\overline{X}=\frac{1}{T}\sum\limits_{t=1}^{T} X_t$ збігається за ймовірністю до значення математичного сподівання $m:$
    \begin{equation*}
        \overline{X} \xrightarrow[T \longrightarrow \infty]{P} m \quad \Longleftrightarrow \quad \forall \varepsilon > 0\ : \lim\limits_{T \longrightarrow \infty} P\left( \Bigl| \frac{1}{T}\sum\limits_{t=1}^{T} X_t - m \Bigr| \geqslant \varepsilon \right) = 0
    \end{equation*}
\end{theorem}

\chapconclude{\ref{chap: review}}

У цьому розділі було розглянуто основний математичний апарат прихованих марковських моделей, необхідний для подальшого дослідження динаміки частково спостережуваного ланцюга Маркова на бінарних послідовностях 

Використовуючи наведені викладки, проведемо у наступному розділі побудову оцінок для шуканих параметрів моделі.