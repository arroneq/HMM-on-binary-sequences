%!TEX root = ../thesis.tex

\chapter{Методи дослідження прихованих марковських моделей}
\label{chap:review}

У цьому розділі будуть окреслені основні поняття та методи, які використовуватимуться в подальших викладках при розв'язуванні поставлених задач.

\section{Основні поняття і властивості ланцюгів Маркова}

Нехай $\left\{ X^t \right\}_{t\geqslant 1}$~--- послідовність випадкових величин зі значеннями в скінченній або зліченній множині $E=\{ e_1,e_2,\ldots \}$. 

\begin{definition}
    Послідовність $\left\{ X^t \right\}_{t\geqslant 1}$ утворює ланцюг Маркова, якщо:
    \begin{align*}
        & \forall t\geqslant 2 \quad \forall i^1,\,i^2,\,\ldots,\,i^{t+1} \in E: \\
	    & P\left( X^{t+1}=i^{t+1} \, |\, X^t=i^t,\,\ldots\,,\, X^1=i^1 \right)=P\left( X^{t+1}=i^{t+1} \, |\, X^t=i^t \right)
    \end{align*}
    Цю умову називають <<умовою марковості>>.
\end{definition}

Множина $E$ називається множиною станів ланцюга, а випадкова величина $X^t$ трактується як стан системи в момент часу $t$. Надалі у ході дослідження по замовчуванню розглядатимуться так звані однорідні ланцюги Маркова, для яких ймовірності переходу з одного стану $i \in E$ в інший $j \in E$ 
\begin{equation*}
    p_{ij} = P\left( X^{t+1}=j\,|\,X^{t}=i \right)
\end{equation*}
не залежать від $t$, тобто
\begin{equation*}
    P\left( X^{2}=j\,|\,X^{1}=i \right) = P\left( X^{3}=j\,|\,X^{2}=i \right) = \ldots = P\left( X^{10}=j\,|\,X^{9}=i \right) = \ldots
\end{equation*}

Ймовірність $p_{ij} = P\left( X^{t+1}=j\,|\,X^{t}=i \right)$ називається перехідною ймовірністю однорідного ланцюга Маркова. Матриця $A$, складена із цих імовірностей, називається матрицею перехідних імовірностей:
\begin{equation*}
    A = \Bigl( p_{ij} \Bigr)_{i,j \in E} = \Bigl( P\left( X^{t+1}=j\,|\,X^{t}=i \right) \Bigr)_{i,j \in E}
\end{equation*} 

Ця матриця є стохастичною, тобто
\begin{equation*}
    \forall i,j \in E: p_{ij} \geqslant 0\ \text{ та }\ \forall i \in E: \sum\limits_{j \in E} p_{ij} = 1
\end{equation*}

Окрім матриці $A$, для характеристики ланцюга Маркова слід задати початковий розподіл
\begin{equation*}
    \pi = \Bigl( \pi_i \Bigr)_{i \in E} = \Bigl( P\left( X^{1} = i \right) \Bigr)_{i \in E}
\end{equation*}

Іншими словами, задається ймовірнісний розподіл, згідно якого відбуватиметься початкова ініціалізація ланцюга на множині станів $E$. При цьому, якщо ініціалізація ланцюга на кожному наступному кроці також відбувається згідно заданого розподілу, то $\pi$ називають інваріантним. Умова інваріантності ланцюга записується таким чином:

\begin{definition}
    Ланцюг Маркова $\left\{ X^t \right\}_{t\geqslant 1}$ з матрицею перехідних імовірностей $A$ та початковим розподілом $\pi = \Bigl( \pi_i \Bigr)_{i \in E}$ є інваріантним, якщо:
    \begin{equation*}
        \pi = \pi A
    \end{equation*}
\end{definition}

Наступна лема~\cite{Serfozo2009} встановлює умови для такого роду перевірки: чи утворює ланцюг Маркова деяка задана послідовність випадкових величин.

\begin{lemma}
    Нехай $\left\{ \xi^t \right\}_{t\geqslant 1}$~--- послідовність незалежних випадкових величин, і нехай $X^1$~--- незалежна від цієї послідовності випадкова величина. Означимо для деякої функції $f:\mathbbm{N}\times E\times E \longrightarrow E$ та при $t \geqslant 1$
    \begin{equation*}
        X^{t+1} = f(t,\,X^t,\,\xi^{t+1})
    \end{equation*}
    Тоді $\left\{ X^t \right\}_{t\geqslant 1}$ утворює ланцюг Маркова на множині станів $E$.
\end{lemma}

Надалі позначатимемо Марковську модель з матрицею перехідних імовірностей $A$ та початковим розподілом $\pi$ як $\lambda=(\pi,\,A)$.

Сформулюємо у теоремі нижче~\cite{Norris1997} ще одну важливу ознаку ланцюгів Маркова~--- так звану <<марковську властивість>>.

\begin{theorem}[<<марковська властивість>>]
    Нехай $\left\{ X^t \right\}_{t\geqslant 1}$~--- ланцюг Маркова $\lambda=(\pi,\,A)$. Тоді для довільного $s \geqslant 2$ та для довідного стану $j \in E$ при умові, що $X^s=j$, послідовність $\left\{ X^{s+t} \right\}_{t\geqslant 1}$ є ланцюгом Маркова з початковим розподілом
    \begin{equation*}
        \delta = (0,\,0,\,\ldots,\,\delta_j,\,0,\,\ldots,\,0),\ \text{де } \delta_j = 1
    \end{equation*}
    та матрицею перехідних імовірностей $A$. Більш того, розподіл випадкових величин $X^{s+1},\,X^{s+2}\,,\ldots$ при $X^s=j$ не залежить від $X^{1},\,X^{2},\,\ldots,\,X^{s-1}:$
    \begin{multline*}
        \forall t\geqslant 1 \quad \forall s\geqslant 2 \quad \forall i^1,\,i^2,\,\ldots,\,i^{t+1},\,j \in E: \\
	    P\left( X^{t+1}=i^{t+1},\,X^t=i^t,\,\ldots\,,\, X^{s+1}=i^{s+1} \,|\, X^{s}=j,\,\ldots,\,X^1=i^1 \right) = \\
        = P\left( X^{t+1}=i^{t+1},\,X^t=i^t,\,\ldots\,,\, X^{s+1}=i^{s+1} \,|\, X^{s}=j \right)
    \end{multline*}
\end{theorem}

Наостанок, зазначимо вигляд скінченновимірних розподілів~\cite{Norris1997} ланцюга Маркова $\lambda=(\pi,\,A)$. Інакше кажучи, визначимо для довільного $t$ сумісну ймовірність перебування системи в станах $i^1,\,i^2,\,\ldots,\,i^{t} \in E$ у послідовні моменти часу:
\begin{equation*}
    P\left( X^{1}=i^{1},\,X^{2}=i^{2},\,\ldots\,,\, X^{t-1}=i^{t-1},\, X^{t}=i^{t} \right) = \pi_{i^1} \cdot p_{i^1i^2} \cdot \ldots \cdot p_{i^{t-1}i^{t}}
\end{equation*}

Таким чином, вказана ймовірність повністю визначається через компонени матриці перехідних імовірностей $A$ та елементи вектора початкового розподілу $\pi$.

\section{Поняття прихованого ланцюга Маркова}

Розглянемо послідовність випадкових величин $\left\{ X^t \right\}_{t\geqslant 1}$ на скінченній або зліченній множині станів $E=\{e_1,e_2,\ldots\}$. Крім того, нехай $\left\{ Y^t \right\}_{t\geqslant 1}$~--- послідовність випадкових величин на скінченній або зліченній множині $F=\{f_1,f_2,\ldots\}$. 

\begin{definition}\label{def: HMM}
    Пара $\left\{\left( X^t,\,Y^t \right)\right\}_{t\geqslant 1}$, задана на декартовому добутку $E\times F$, є прихованою Марковською моделлю за виконання таких умов:
    \begin{enumerate}
        \item послідовність $\left\{ X^t \right\}_{t\geqslant 1}$ утворює ланцюг Маркова з початковим розподілом $\pi$ та матрицею перехідних імовірностей $A$;
        \item послідовність $\left\{\left( X^t,\,Y^t \right)\right\}_{t\geqslant 1}$ є ланцюгом Маркова;
        \item випадкові величини $Y^1,\,Y^2,\,\ldots,\,Y^t$ є умовно незалежними при заданому наборі величин $X^1,\,X^2,\,\ldots,\,X^t:$
        \begin{multline*}
            \forall t\geqslant 2 \quad \forall j^1,\,j^2,\,\ldots,\,j^t \in F \quad \forall i^1,\,i^2,\,\ldots,\,i^t \in E: \\
            P\left( Y^1=j^1,\,\ldots,\,Y^t=j^t \,|\, X^1=i^1,\,\ldots,\,X^t=i^t \right) = \\
            = \prod\limits_{k=1}^{t}P\left( Y^k=j^k \,|\, X^1=i^1,\,\ldots,\,X^t=i^t \right)
        \end{multline*}
        \item умовний розподіл випадкової величини $Y^k$ в момент часу $k$ при заданих $X^1,\,X^2,\,\ldots,\,X^t$ залежить лише від $X^k:$
        \begin{align*}
            & \forall t\geqslant 2 \quad \forall k=\overline{1,t} \quad \forall j^k \in F \quad \forall i^1,\,i^2,\,\ldots,\,i^t \in E: \\
            & P\left( Y^k=j^k \,|\, X^1=i^1,\,\ldots,\,X^t=i^t \right) = P\left( Y^k=j^k \,|\, X^k=i^k \right)
        \end{align*}
    \end{enumerate}
\end{definition}

У парі $\left\{\left( X^t,\,Y^t \right)\right\}_{t\geqslant 1}$ послідовність $\left\{ X^t \right\}_{t\geqslant 1}$ називають <<прихованою>>, а послідовність $\left\{ Y^t \right\}_{t\geqslant 1}$~--- <<спостережуваною>>. Фактично, в таких термінах в Озн.~\ref{def: HMM} умови 3) та 4) в сукупності вказують на взаємозв'язок спостережень та прихованих станів виключно через поточний момент часу.

Окрім матриці $A$ та вектора $\pi$, властивих ланцюгу Маркова $\left\{ X^t \right\}_{t\geqslant 1}$, прихована Марковська модель визначається матрицею умовних імовірностей спостережень $j \in F$ при заданих прихованих станах $i \in E:$
\begin{equation*}
    B = \Bigl( B_{ij} \Bigr)_{i,j \in E \times F} = \Bigl( P\left( Y^{t}=j \,|\, X^{t}=i \right) \Bigr)_{i,j \in E \times F}
\end{equation*} 

Позначатимемо приховану Марковську модель з початковим розподілом $\pi$, матрицею перехідних імовірностей $A$ та матрицею умовних ймовірностей спостережень при заданих прихованих станах $B$ таким чином: $\lambda=(\pi,\,A,\,B)$.

\section{Ітераційний алгоритм Баума-Велша}

Нехай протягом деякого часу $t=\overline{1,T}$ спостерігається послiдовність випадкових величин 
\begin{equation*}
    \left( Y^1=y^1,\,\ldots,\,Y^T=y^T \right) \Longleftrightarrow Y=y,
\end{equation*}
деякої прихованої Марковської моделі, ознаки $\lambda=(\pi,\,A,\,B)$ якої є невідомими. Постає питання так званої задачі навчання: як за набором наявних даних віднайти оптимальні параметри моделі?

Скористаємося методом максимальної правдоподібності, шукаючи оцінку $\lambda^*=(\pi^*,\,A^*,\,B^*)$ шляхом максимізації ймовірності вигляду:
\begin{equation}\label{eq: likelihood function}
    \lambda^{*}=\argmax\limits_{\lambda} P\left( Y=y \,|\, \lambda \right)
\end{equation}

Інакше кажучи, шукатимемо такі параметри моделi, якi найкраще пояснюють отриманi спостереження $y$. 

Ймовірність $P\left( Y=y \,|\, \lambda \right)$ називається функцією правдоподібності. І у випадку прихованих Марковських моделей безпосередня максимізація цієї функції через, наприклад, диференціювання по відповідним невідомим параметрам часто є складною аналітично чи неможливою в цілому задачею в силу громіздкості отриманого виразу.

Однак, для Марковських моделей можна застосувати інший підхід: модифікацію ЕМ-алгоритму~\cite[розділ 4]{Koski2001} для дослідження прихованих ланцюгів Маркова~--- ітераційний алгоритм Баума-Велша~\cite[розділ 15]{Koski2001}. 

Задавши деяке наближення невідомої моделі $\lambda^{(0)}=(\pi^{(0)},\,A,^{(0)},\,B^{(0)})$, покладемо для наступної ітерації $n+1$
\begin{equation*}
    \lambda^{(n+1)} = \argmax\limits_{\lambda} Q\left( \lambda^{(n)},\,\lambda \right),
\end{equation*}
де
\begin{equation}\label{eq: Q quasi-log likelihood function}
    Q\left( \lambda^{(n)},\,\lambda \right) = \sum\limits_{x \in E^T}L_{\lambda^{(n)}}\cdot\ln L_{\lambda}
\end{equation}
є так званою функцією квазі-log правдоподібності, а вираз
\begin{equation*}
    L_{\lambda} \equiv P\left( X=x,\,Y=y \,|\, \lambda \right)
\end{equation*}
називається повною функцією правдоподібності.

Доведено~\cite[розділ 4]{Koski2001}, що така ітераційна процедура є збіжною і приводить до точки локального максимуму логарифму функції правдоподібності~\eqref{eq: likelihood function}. А оскільки у довільної функції та у відповідної логарифмічної функції від неї точки екстремумів є однаковими, ця процедура повністю задовільняє поставлену задачу.

В залежності від специфіки системи (характер динаміки; особливість прихованих станів ланцюга; повноцінність, частковість чи зашумленість наявних спостережень), явний аналітичний вигляд результату максимізації функції~\eqref{eq: Q quasi-log likelihood function} для кожної окремо заданої прихованої Марковської моделі є різним.

Тим не менш, серед загальних особливостей можна виокремити наявність в отриманих ітераційних формулах переоцінки невідомих параметрів так званих коефіцієнтів прямого~\eqref{eq: alpha, forward algorithm coefficients} та зворотного ходу~\eqref{eq: beta, backward algorithm coefficients}.

Вказані коефіцієнти визначаються наступним чином:
\begin{align}
    & \forall x \in E: \notag \\
    & \alpha_t(x) = P\left( Y^1=y^1,\,\ldots,\,Y^t=y^t,\,X^t=x \,|\, \lambda^{(n)} \right) \label{eq: alpha, forward algorithm coefficients} \\
    & \beta_t(x) = P\left( Y^{t+1}=y^{t+1},\,\ldots,\,Y^T=y^T \,|\, X^t=x,\, \lambda^{(n)} \right) \label{eq: beta, backward algorithm coefficients}
\end{align}

Крім того, вказані ймовірності можна визначити рекурентно~\cite[розділ 5]{Nilsson2005}. Відповідні рекурентні співвідношення наведені нижче для коефіцієнтів прямого ходу
\begin{align*}
    & t = 1              && \forall x \in E: \alpha_1(x)=\pi_{x}\,B_{x,y^1} \\
    & t = \overline{2,T} && \forall x \in E: \alpha_{t}(x)=\sum\limits_{x'\in E}\alpha_{t-1}(x')\,A_{x'x}\,B_{xy^{t}} 
\end{align*}
та коефіцієнтів зворотного ходу
\begin{align*}
    & t = T                && \forall x \in E: \beta_T(x)=1 \\
    & t = \overline{T-1,\,1} && \forall x \in E: \beta_t(x)=\sum\limits_{x' \in E}\beta_{t+1}(x')\,A_{x x'}\,B_{x'y^{t+1}}
\end{align*}

\begin{remark}
    При великих значеннях довжини ланцюга виникає потреба у шкалюванні~\cite[розділ 5]{Nilsson2005} коефіцієнтів прямого та зворотного ходу, адже їхні значення стають нерозрізнювано малими для обчислювальних ресурсів. Процедура шкалювання полягає в наступному: на кожному кроці $t$ після обчислення істинних~\eqref{eq: alpha, forward algorithm coefficients} слід виконати відповідне нормування
    \begin{align*}
        \forall x \in E: && \widehat{\alpha}_t(x) = \frac{\alpha_t(x)}{C_t},\ \text{де}\ C_t = \sum\limits_{x' \in E}\alpha_t(x'),
    \end{align*}
    а тоді коефіцієнти~\eqref{eq: beta, backward algorithm coefficients} переоцінюватимуться так:
    \begin{align*}
        \forall x \in E: && \widehat{\beta}_t(x) = \frac{\beta_t(x)}{C_t}
    \end{align*}
\end{remark}

\section{Алгоритм Вітербі}

Отримавши за наявними спостереженнями оптимальну модель $\lambda^*=(\pi^*,\,A^*,\,B^*)$, перейдемо до так званої задачі декодування: віднайдемо ланцюжок прихованих станів системи. Алгоритм, який дозволяє ефективно розв’язати задачу декодування, називається алгоритмом Вiтербi~\cite[розділ 6]{Nilsson2005}.

Отже, шукатимемо таку послідовність прихованих станів $\widehat{X}^1,\,\widehat{X}^2,\,\ldots,\,\widehat{X}^T$, яка найкращим чином описує наявні спостереження:
\begin{equation*}
    \widehat{X} = \argmax\limits_{x \in E^T} P\left( X=x,\,Y=y \,|\, \lambda^* \right)
\end{equation*}

Введемо величини $\delta_t(x)$~--- ймовірності спостереження ланцюжка довжини $t$, використовуючи найкращий шлях, що закiнчується станом $x \in E$ в момент часу $t:$
\begin{equation*}
    \delta_t(x)=\max_{x^1,\ldots,\,x^{t-1}}P\left( X^1=x^1,\,\ldots,\,X^t=x,\,Y^1=y^1,\,\ldots,\,Y^t=y^t \,|\, \lambda^*  \right)
\end{equation*}

Вказані ймовірності можна визначити рекурентно:
\begin{align*}
    & t = 1              && \forall x \in E: \delta_1(x)=\pi_{x}\,B_{xy^1} \\
    & t = \overline{2,T} && \forall x \in E: \delta_{t}(x)=B_{xy^{t}}\cdot\max_{x' \in E}\{\delta_{t-1}(x')\,A_{x'x}\}
\end{align*}

При цьому, щоб знайти оптимальний ланцюжок прихованих станiв, необхідно вiдстежувати аргумент, при якому досягається максимум $\delta_t(x)$ для кожного $t$ та $x$. Таким чином, алгоритм Вiтербi знаходження найбiльш ймовiрного ланцюжка прихованих станiв є таким:

\begin{enumerate}
    \item ініціалізація:
    \begin{align*}
        &\forall x \in E: && \delta_1(x)=\pi_{x}B_{xy^1}, \ \psi_1(x)=1
    \end{align*}    
    \item обчислити коефіцієнти $\delta_t(x)$ та відповідні аргументи $\psi_t(x):$
    \begin{align*}
        &\forall t=\overline{1,T}, \ \forall x \in E: && \delta_{t}(x)=B_{xy^{t}}\cdot\max_{x'\in E}\{\delta_{t-1}(x')\,A_{x'x}\} \\
        &\forall t=\overline{1,T}, \ \forall x \in E: && \psi_{t}(x)=\argmax_{x'\in E}\{\delta_{t-1}(x')\,A_{x'x}\}
    \end{align*}
    \item покласти зворотну точку відліку:
    \begin{align*}
        &\widehat{\delta}=\max_{x \in E}\{\delta_T(x)\} \\
        &\widehat{\psi}=\argmax_{x \in E}\{\delta_T(x)\}
    \end{align*}
    \item визначити оптимальний ланцюжок станів (у зворотному порядку), починаючи з останнього $\widehat{x}^T=\widehat{\psi}:$
    \begin{align*}
        &\forall t=\overline{T-1,\,1}: && \widehat{x}^t=\psi_{t+1}(\widehat{x}^{t+1})
    \end{align*}
\end{enumerate}

\section{Статистика на ланцюгах Маркова}

Окреслимо основні інструменти математисної статистики, які будуть використані при побудові статистичних оцінок невідомих параметрів.

Вектор незалежних однаково розподілених випадкових величин $X^1,\,\ldots,\,X^T$ з деякого розподілу $F(\theta)$ називають вибіркою об'єму $T$. При цьому, параметр розподілу $\theta$ може бути невідомим. Функція від вибірки $S_T=S_T(\vv{X})$ називається статистикою. 

Якщо значення статистики $S_T(\vv{X})$ при заданій реалізації вибірки приймає наближене значення невідомого параметра розподілу $\theta$, тоді $S_T$ називають точковою оцінкою $\theta$. 

\begin{definition}
    Статистика $S_T$ називається змістовною оцінкою $\theta$, якщо вона збігається за ймовірністю до істинного значення оцінюваного параметра, тобто 
    \begin{equation*}
        S_T \xrightarrow[T \longrightarrow \infty]{P} \theta \quad \Longleftrightarrow \quad \forall \varepsilon > 0 : \lim\limits_{T \longrightarrow \infty} P\bigl( |S_T - \theta| \geqslant \varepsilon \bigr) = 0
    \end{equation*}
\end{definition}

\begin{definition}
    Статистика $S_T$ називається незміщеною оцінкою $\theta$, якщо її математичне сподівання дорівнює істинному значенню оцінюваного параметра, тобто
    \begin{equation*}
        MS_T = \theta
    \end{equation*}
\end{definition}

Також зазначимо для набору незалежних однаково розподілених випадкових величин так званий Закон великих чисел~\cite{Larsen2017}:

\begin{theorem}
    Нехай $X^1,\,\ldots,\,X^T$~--- незалежні однаково розподілені випадкові величини зі скінченними математичними сподіваннями $\forall k=\overline{1,T} : MX^k=m<\infty$ та дисперсіями $\forall k=\overline{1,T} : DX^k=\sigma^2<\infty$, тоді вибіркова дисперсія $\overline{X}$ збігається за ймовірністю до значення математичного сподівання заданої вибірки:
    \begin{equation*}
        \overline{X} \xrightarrow[T \longrightarrow \infty]{P} m \quad \Longleftrightarrow \quad \forall \varepsilon > 0 : \lim\limits_{T \longrightarrow \infty} P\left( \Bigl| \frac{1}{T}\sum\limits_{k=1}^{T} X^k - m \Bigr| \geqslant \varepsilon \right) = 0
    \end{equation*}
\end{theorem}

\chapconclude{\ref{chap:review}}

Розглядаючи динаміку бінарних послідовностей протягом певного часу при наявних опосередкованих даних про неї, у наступному розділі будуть розв'зані задачі оцінки деяких характеристик зазначної моделі. При цьому, важливо перконатися, що модель відповідатиме умовам використання окреслених у цьому розділі алгоритмів та методів. 